{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0052264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob==0.9.0\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee2bf77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter  as tk\n",
    "import nltk \n",
    "from textblob import TextBlob\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5173c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://datascientest.com/foot-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08d81a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(url, language = 'fr')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0704cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"L'IA no code annonce-t-elle la mort du data scientist ?\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ce279ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antoine Crochet-Damais']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05391a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Les plateformes de machine learning sans code ne cessent de se multiplier. Une nouvelle génération d\\'outils qui pose la question du devenir du scientifique des données.\\n\\nAlteryx, Azure ML Studio, Dataiku, DataRobot, H2O.ai... Les plateformes de machine learning sans code se multiplient comme des petits pains. Leur promesse ? Mettre la création d\\'IA à la portée des professionnels non-informaticiens qui deviendraient alors des citizen data scientists. Une population qui peut via ces solutions intégrer à la volée des sources de données multiples et recourir à des technologies d\\'automatisation du machine learning (auto ML) pour générer ses modèles de prédiction. \"Les solutions d\\'auto ML permettent de produire rapidement des modèles qui restent en général assez simples. L\\'objectif des éditeurs étant d\\'aboutir à une IA explicable\", commente Ismaïl Lachheb, data scientist au sein du cabinet de conseil français Octo Technology (groupe Accenture). Une vision produit qui est suivie par exemple par Alteryx.\\n\\nAuto ML\\n\\nEn fonction d\\'un problème donné, l\\'auto ML compare plusieurs types d\\'algorithme mais aussi des algorithmes de même catégorie avec des réglages différents en termes d\\'hyperparamètres. Le but : dénicher la configuration qui donnera les meilleurs résultats. \"C\\'est un moyen de gagner du temps en cernant assez vite ce qu\\'il est possible de faire\", reconnait Sergio Winter, machine learning engineer chez Revolve, entité de l\\'ESN Devoteam experte en AWS. \"Les modèles résultant de ce processus pourront néanmoins se révéler difficiles à déployer en l\\'état.\"\\n\\nPremier bémol : le choix des hyperparamètres n\\'est pas neutre. \"Il est souvent nécessaire que le data scientist interprète les conséquences du choix des paramètres pour les métiers\", prévient Didier Gaultier, directeur data science et IA chez Business & Decision (groupe Orange). \"Dans un moteur de recommandation par exemple, un seuil de classement aura un impact direct sur le chiffre d\\'affaires, la marge, et la proportion de population adressée lors d\\'une campagne marketing.\"\\n\\n\"L\\'auto ML passe à côté du feature engineerig qui consiste à préparer, raffiner, un peu comme on raffine du pétrole en essence, et enrichir les données en entrée du modèle\"\\n\\nDidier Gaultier d\\'ajouter : \"L\\'auto ML passe aussi à côté du feature engineerig qui consiste à préparer, raffiner, un peu comme on raffine du pétrole en essence, et enrichir les données en entrée du modèle.\" Le consultant insiste : \"On pourra recoder telle ou telle variable pour que sa distribution soit compatible avec le type d\\'algorithme utilisé. On pourra aussi croiser tel prédicteur avec tel autre pour créer un indicateur plus pertinent en entrée de l\\'algorithme. C\\'est là où l\\'impact du raisonnement humain sur le résultat final a le plus importance, et c\\'est principalement le soin apporté lors de cette phase qui va caractériser la compétence d\\'un(e) data scientist(e).\"\\n\\nPlus la problématique métier sera complexe, plus le travail de feature engineering devra être potentiellement approfondi. \"Dans le domaine maritime par exemple, les numéros d\\'identification des containers répondent à un format de description spécifique avec des suites de numéros permettant d\\'identifier le propriétaire, l\\'opérateur, le type de containers, les containers réfrigérés...\", égraine Sergio Winter. L\\'ensemble de ces éléments devra être pris en compte dans l\\'ingénierie des fonctionnalités… et seul un data scientist pourra réaliser ces rapprochements. \"Les solutions d\\'IA no code permettent à l\\'utilisateur final d\\'avoir plus de contrôle sur les modèles. Ce qui n\\'est pas une mauvaise chose. Mais cela ne supprime pas tout le travail de science de la donnée\", résume Sergio Winter.\\n\\nLe no code ne peut pas saisir la data\\n\\nIsmaïl Lachheb insiste : \"Les plateformes d\\'IA no code se concentrent avant tout sur le choix des modèles et des hyperparamètres. Mais le gros d\\'un projet d\\'un machine learning, qui reste couvert par le data scientist, consiste à comprendre la data, son mode de production, en maîtriser les biais, mais aussi à nettoyer et préparer les données.\" Ismaïl Lachheb enchaîne : \"Prédire le comportement d\\'un processus de production industrielle implique d\\'intégrer, fédérer et maitriser différents flux de données en provenance de capteurs de température, ou de tension, installés à différents endroits d\\'une chaîne de fabrication. Les outils d\\'IA no code sont loin d\\'être capables de modéliser une telle complexité.\"\\n\\nEn aval, le no code facilite la mise en production des modèles de machine learning avant leur réentrainement. Sur le front du MLOps, des plateformes d\\'IA comme Dataiku ou DataRobot intègrent des environnements no code taillés pour gérer l\\'ensemble du cycle de vie d\\'un modèle, de l\\'apprentissage à sa mise en production (lire l\\'article Comparatif MLOps : Dataiku et DataRobot face aux alternatives open source). Octo s\\'inspire d\\'ailleurs de cette logique via son offre d\\'IA Factory. \"En parallèle de l\\'émergence du no code, les data scientits ont de plus en plus tendance à se spécialiser soit dans le MLOps, soit dans un des nombreux domaines de l\\'IA, tels la vision par ordinateur, le traitement automatique du langage ou le reinforcement learning\", constate Ismaïl Lachheb. Le scientifique de la donnée a encore de beaux jours devant lui.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "236218d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les plateformes de machine learning sans code ne cessent de se multiplier. Une nouvelle génération d'outils qui pose la question du devenir du scientifique des données.\n",
      "\n",
      "Alteryx, Azure ML Studio, Dataiku, DataRobot, H2O.ai... Les plateformes de machine learning sans code se multiplient comme des petits pains. Leur promesse ? Mettre la création d'IA à la portée des professionnels non-informaticiens qui deviendraient alors des citizen data scientists. Une population qui peut via ces solutions intégrer à la volée des sources de données multiples et recourir à des technologies d'automatisation du machine learning (auto ML) pour générer ses modèles de prédiction. \"Les solutions d'auto ML permettent de produire rapidement des modèles qui restent en général assez simples. L'objectif des éditeurs étant d'aboutir à une IA explicable\", commente Ismaïl Lachheb, data scientist au sein du cabinet de conseil français Octo Technology (groupe Accenture). Une vision produit qui est suivie par exemple par Alteryx.\n",
      "\n",
      "Auto ML\n",
      "\n",
      "En fonction d'un problème donné, l'auto ML compare plusieurs types d'algorithme mais aussi des algorithmes de même catégorie avec des réglages différents en termes d'hyperparamètres. Le but : dénicher la configuration qui donnera les meilleurs résultats. \"C'est un moyen de gagner du temps en cernant assez vite ce qu'il est possible de faire\", reconnait Sergio Winter, machine learning engineer chez Revolve, entité de l'ESN Devoteam experte en AWS. \"Les modèles résultant de ce processus pourront néanmoins se révéler difficiles à déployer en l'état.\"\n",
      "\n",
      "Premier bémol : le choix des hyperparamètres n'est pas neutre. \"Il est souvent nécessaire que le data scientist interprète les conséquences du choix des paramètres pour les métiers\", prévient Didier Gaultier, directeur data science et IA chez Business & Decision (groupe Orange). \"Dans un moteur de recommandation par exemple, un seuil de classement aura un impact direct sur le chiffre d'affaires, la marge, et la proportion de population adressée lors d'une campagne marketing.\"\n",
      "\n",
      "\"L'auto ML passe à côté du feature engineerig qui consiste à préparer, raffiner, un peu comme on raffine du pétrole en essence, et enrichir les données en entrée du modèle\"\n",
      "\n",
      "Didier Gaultier d'ajouter : \"L'auto ML passe aussi à côté du feature engineerig qui consiste à préparer, raffiner, un peu comme on raffine du pétrole en essence, et enrichir les données en entrée du modèle.\" Le consultant insiste : \"On pourra recoder telle ou telle variable pour que sa distribution soit compatible avec le type d'algorithme utilisé. On pourra aussi croiser tel prédicteur avec tel autre pour créer un indicateur plus pertinent en entrée de l'algorithme. C'est là où l'impact du raisonnement humain sur le résultat final a le plus importance, et c'est principalement le soin apporté lors de cette phase qui va caractériser la compétence d'un(e) data scientist(e).\"\n",
      "\n",
      "Plus la problématique métier sera complexe, plus le travail de feature engineering devra être potentiellement approfondi. \"Dans le domaine maritime par exemple, les numéros d'identification des containers répondent à un format de description spécifique avec des suites de numéros permettant d'identifier le propriétaire, l'opérateur, le type de containers, les containers réfrigérés...\", égraine Sergio Winter. L'ensemble de ces éléments devra être pris en compte dans l'ingénierie des fonctionnalités… et seul un data scientist pourra réaliser ces rapprochements. \"Les solutions d'IA no code permettent à l'utilisateur final d'avoir plus de contrôle sur les modèles. Ce qui n'est pas une mauvaise chose. Mais cela ne supprime pas tout le travail de science de la donnée\", résume Sergio Winter.\n",
      "\n",
      "Le no code ne peut pas saisir la data\n",
      "\n",
      "Ismaïl Lachheb insiste : \"Les plateformes d'IA no code se concentrent avant tout sur le choix des modèles et des hyperparamètres. Mais le gros d'un projet d'un machine learning, qui reste couvert par le data scientist, consiste à comprendre la data, son mode de production, en maîtriser les biais, mais aussi à nettoyer et préparer les données.\" Ismaïl Lachheb enchaîne : \"Prédire le comportement d'un processus de production industrielle implique d'intégrer, fédérer et maitriser différents flux de données en provenance de capteurs de température, ou de tension, installés à différents endroits d'une chaîne de fabrication. Les outils d'IA no code sont loin d'être capables de modéliser une telle complexité.\"\n",
      "\n",
      "En aval, le no code facilite la mise en production des modèles de machine learning avant leur réentrainement. Sur le front du MLOps, des plateformes d'IA comme Dataiku ou DataRobot intègrent des environnements no code taillés pour gérer l'ensemble du cycle de vie d'un modèle, de l'apprentissage à sa mise en production (lire l'article Comparatif MLOps : Dataiku et DataRobot face aux alternatives open source). Octo s'inspire d'ailleurs de cette logique via son offre d'IA Factory. \"En parallèle de l'émergence du no code, les data scientits ont de plus en plus tendance à se spécialiser soit dans le MLOps, soit dans un des nombreux domaines de l'IA, tels la vision par ordinateur, le traitement automatique du langage ou le reinforcement learning\", constate Ismaïl Lachheb. Le scientifique de la donnée a encore de beaux jours devant lui.\n"
     ]
    }
   ],
   "source": [
    "print(article.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "738f3ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les plateformes de machine learning sans code ne cessent de se multiplier.\n",
      "Alteryx, Azure ML Studio, Dataiku, DataRobot, H2O.ai... Les plateformes de machine learning sans code se multiplient comme des petits pains.\n",
      "L'ensemble de ces éléments devra être pris en compte dans l'ingénierie des fonctionnalités… et seul un data scientist pourra réaliser ces rapprochements.\n",
      "Mais le gros d'un projet d'un machine learning, qui reste couvert par le data scientist, consiste à comprendre la data, son mode de production, en maîtriser les biais, mais aussi à nettoyer et préparer les données.\"\n",
      "En aval, le no code facilite la mise en production des modèles de machine learning avant leur réentrainement.\n"
     ]
    }
   ],
   "source": [
    "print(article.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fda70be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antoine Crochet-Damais']\n"
     ]
    }
   ],
   "source": [
    "print(article.authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbee3b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(article.publish_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5ba7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise() :\n",
    "    url = utext.get('1.0',\"end\").strip()\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "    \n",
    "    title.config(state= 'normal')\n",
    "    author.config(state = 'normal')\n",
    "    publication.config(state = 'normal')\n",
    "    summary.config(state = 'normal')\n",
    "    sentiment.config(state = 'normal')\n",
    "    \n",
    "    title.delete('1.0','end')\n",
    "    title.insert('1.0', article.title)\n",
    "    \n",
    "    author.delete('1.0','end')\n",
    "    author.insert('1.0', article.authors)\n",
    "    \n",
    "    publication.delete('1.0', 'end')\n",
    "    publication.insert('1.0',  article.publish_date or '-none-')\n",
    "    \n",
    "    summary.delete('1.0','end')\n",
    "    summary.insert('1.0', article.summary)\n",
    "    \n",
    "    sentiment.delete('1.0', 'end')\n",
    "    analysis= TextBlob(article.text)\n",
    "    \n",
    "    if analysis.polarity > 0:\n",
    "        sentiment.insert('1.0', \"Positif\")\n",
    "    elif analysis.polarity < 0:\n",
    "        sentiment.insert('1.0', \"Negatif\")\n",
    "    else : \n",
    "        sentiment.insert('1.0', \"Neutre\")\n",
    "        \n",
    "    title.config(state = 'disabled')\n",
    "    author.config(state = 'disabled')\n",
    "    publication.config(state = 'disabled')\n",
    "    summary.config(state = 'disabled')\n",
    "    sentiment.config(state = 'disabled')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb39aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title('Article Summary')\n",
    "root.geometry('1200x600')\n",
    "\n",
    "tlabel=tk.Label(root, text = 'Titre')\n",
    "tlabel.pack()\n",
    "title = tk.Text(root, height=1, width = 140 )\n",
    "title.config(state='disabled', bg = '#dddddd')\n",
    "title.pack()\n",
    "\n",
    "alabel=tk.Label(root, text = 'Auteurs')\n",
    "alabel.pack()\n",
    "author = tk.Text(root, height=1, width = 140 )\n",
    "author.config(state='disabled', bg = '#dddddd')\n",
    "author.pack()\n",
    "\n",
    "plabel=tk.Label(root, text = 'Date de publication')\n",
    "plabel.pack()\n",
    "publication = tk.Text(root, height=1, width = 140 )\n",
    "publication.config(state='disabled', bg = '#dddddd')\n",
    "publication.pack()\n",
    "\n",
    "slabel=tk.Label(root, text = 'Résumé')\n",
    "slabel.pack()\n",
    "summary = tk.Text(root, height=10, width = 140 )\n",
    "summary.config(state='disabled', bg = '#dddddd')\n",
    "summary.pack()\n",
    "\n",
    "selabel=tk.Label(root, text = 'Analyse des sentiments')\n",
    "selabel.pack()\n",
    "sentiment = tk.Text(root, height=1, width = 140 )\n",
    "sentiment.config(state='disabled', bg = '#dddddd')\n",
    "sentiment.pack()\n",
    "\n",
    "\n",
    "ulabel = tk.Label(root, text = 'URL')\n",
    "ulabel.pack()\n",
    "utext = tk.Text(root, height=1, width = 140 )\n",
    "utext.pack()\n",
    "\n",
    "btn = tk.Button(root, text = 'Lancer la recherche', command = summarise)\n",
    "btn.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
